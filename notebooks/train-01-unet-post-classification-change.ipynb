{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net Segmantic Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_FOLDER = Path.cwd().parent\n",
    "sys.path.append(str(BASE_FOLDER))\n",
    "\n",
    "wandb_project = \"unet_change\"\n",
    "logging = \"remote\"\n",
    "wandb_key = \"YOUR_WANDB_API_KEY_HERE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.trainers.unet_segmentation.train import train_model\n",
    "\n",
    "datamodule, task, trainer = train_model(\n",
    "    logging=logging,\n",
    "    wandb_project=wandb_project,\n",
    "    wandb_key=wandb_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sweeps\n",
    "\n",
    "### 1 - Sweep Resnet18\n",
    "\n",
    "```config-sweep-resnet18.yaml```\n",
    "\n",
    "Testing different batch size, patch size, number of training batches per epoch, use of pretrained model weights with Resnet18 backbone.\n",
    "\n",
    "Batch size, patch size, training batches: No significant trend observable. Pretrained model weights = True seems to work better.\n",
    "\n",
    "### 2 - Sweep Backbones\n",
    "\n",
    "Testing different backbones:\n",
    "- resnet50: No outstanding performance\n",
    "- resnext50_32x4d: Better with 512 training batches. ValJaccard ~0.25\n",
    "- efficientnet-b4: Requires many GPU ressources, but better perfomance than other backbones. 512 training batches leads to good results faster than 1024. ValJaccard ~0.27\n",
    "- mit_b2: Performance similar to efficientnet-b4. ValJaccard ~0.27\n",
    "- HRNet https://doi.org/10.3390/rs13163087: Not working with torchgeo.\n",
    "- MobileNet v4: https://doi.org/10.48550/arXiv.2404.10518\n",
    "\n",
    "### 3 - Sweep Input Bands\n",
    "\n",
    "Adding more bands with every training (mit_b2, batch size 32, patch size 256)\n",
    "- Generally: The more the better\n",
    "- IoU:\n",
    "    - RGB: 0.07\n",
    "    - RGB + CIR: 0.1\n",
    "    - RGB + CIR + Elevation: 0.2\n",
    "    - RGB + CIR + Elevation + Derived Layers: 0.25\n",
    "- Adding Spot-4 data (```sweep-spot-4```) does *not* lead to significantly higher scores!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.trainers.unet_segmentation_sweep.sweep import start_sweep\n",
    "\n",
    "start_sweep()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load saved Datamodule and Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.trainers.utils import load_config_from_yaml\n",
    "\n",
    "experiment_dir = Path(\"../models/best-parameters-4.3\")\n",
    "config = load_config_from_yaml(experiment_dir / \"config.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get datamodule and task if not already loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import yaml\n",
    "\n",
    "from src.trainers.unet_segmentation.unet_segmentation import MultiClassSemanticSegmentationTask\n",
    "from src.trainers.unet_segmentation.train import get_datamodule\n",
    "\n",
    "# Load task\n",
    "with open(experiment_dir / \"model_paths.yaml\", \"r\") as file:\n",
    "    model_path = yaml.safe_load(file)[\"best_model_path\"]\n",
    "task = MultiClassSemanticSegmentationTask.load_from_checkpoint(experiment_dir / model_path)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "task.to(device).eval()\n",
    "\n",
    "# Get datamodule\n",
    "datamodule = get_datamodule(\n",
    "    config=config,\n",
    "    prediction_year=2024,\n",
    ")\n",
    "datamodule.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Samples from Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = task.plot_prediction_samples(\n",
    "    datamodule=datamodule,\n",
    "    experiment_dir=experiment_dir,\n",
    "    n_samples=6,\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchgeo.datasets import BoundingBox\n",
    "import wandb\n",
    "\n",
    "from src.inference.eval import infer_on_whole_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on Cross-Temporal Prediction Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference:  28%|██▊       | 5285/18634 [17:27<54:35,  4.08it/s]  "
     ]
    }
   ],
   "source": [
    "datamodule.num_workers = 0\n",
    "\n",
    "roi = None #BoundingBox(minx=470800, maxx=473000, miny=5270500, maxy=5272000, mint=0.0, maxt=9.223372036854776e+18) # Define a small test ROI\n",
    "infer_on_whole_image(\n",
    "    datamodule=datamodule,\n",
    "    task=task,\n",
    "    experiment_dir=experiment_dir,\n",
    "    overlap=64,\n",
    "    delta=8,\n",
    "    predict_on_test_ds=False,\n",
    "    roi=roi,\n",
    "    output_filename=\"prediction_cross-temporal_2024\",\n",
    "    inference_batch_size=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.num_workers = 0\n",
    "\n",
    "roi = None #BoundingBox(minx=470800, maxx=473000, miny=5270500, maxy=5272000, mint=0.0, maxt=9.223372036854776e+18) # Define a small test ROI\n",
    "infer_on_whole_image(\n",
    "    datamodule=datamodule,\n",
    "    task=task,\n",
    "    experiment_dir=experiment_dir,\n",
    "    overlap=64,\n",
    "    delta=8,\n",
    "    predict_on_test_ds=False,\n",
    "    roi=roi,\n",
    "    output_filename=\"prediction_cross-temporal_2020\",\n",
    "    inference_batch_size=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule.num_workers = 0\n",
    "\n",
    "roi = None #BoundingBox(minx=470800, maxx=473000, miny=5270500, maxy=5272000, mint=0.0, maxt=9.223372036854776e+18) # Define a small test ROI\n",
    "infer_on_whole_image(\n",
    "    datamodule=datamodule,\n",
    "    task=task,\n",
    "    experiment_dir=experiment_dir,\n",
    "    overlap=64,\n",
    "    delta=8,\n",
    "    predict_on_test_ds=True,\n",
    "    roi=roi,\n",
    "    output_filename=\"prediction_in-domain_2013\",\n",
    "    inference_batch_size=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Change Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.inference.eval import generate_change_map\n",
    "from src.trainers.utils import compute_final_metrics\n",
    "\n",
    "data_folder = Path(\"D:/Nextcloud/HabitAlp2.0/Originaldaten\")\n",
    "experiment_dir = data_folder / \"model_output/clay_v1_base_rgb_cir_ndsm/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Map with Cross-Temporal Prediction Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_change_map(\n",
    "    mask_path=\"D:/Nextcloud/HabitAlp2.0/Originaldaten/processed/mask/classes_v3_2013.tif\",#datamodule.mask_path,\n",
    "    prediction_path=experiment_dir / \"training_rois_2020_model-f64vg6b6_v40_mIoU=0.3306.tif\",\n",
    "    output_path=experiment_dir / \"change_map_2013-2020-f64vg6b6_v40.tif\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\n",
    "    \"No change\",\n",
    "    \"Mature Tree Density Loss\",\n",
    "    \"Old Growth Density Loss\",\n",
    "    \"Forest Setback YoungLoss\",\n",
    "    \"Forest Stage Progression\",\n",
    "    \"Forest Density Gain\",\n",
    "    \"Early Forest Establishment\",\n",
    "    \"Clearcut Loss\",\n",
    "    \"Other Transition\"]\n",
    "\n",
    "#class_names = [\n",
    "#    \"No change\",\n",
    "#    \"Change\"\n",
    "#]\n",
    "\n",
    "num_classes = len(class_names)\n",
    "\n",
    "multiclass_metrics, metrics_each_label, figure_collection = compute_final_metrics(\n",
    "    reference_change_map=data_folder / \"habitalp_change/habitalp_change_2013_2020.tif\",\n",
    "    prediction_change_map=experiment_dir / \"change_map_2013-2020_roi_example-ocg72h08_v97.tif.tif\",\n",
    "    num_classes=num_classes, # 9 classes to take no change and index into account\n",
    "    class_names=class_names,\n",
    ")\n",
    "\n",
    "print(multiclass_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with wandb.init(project=wandb_project, id=\"nt7lhzek\", resume=\"must\") as run:\n",
    "    if num_classes == 2:\n",
    "        metric_name = \"change_metrics_binary\"\n",
    "        # log Multiclass metrics\n",
    "        run.summary[metric_name] = multiclass_metrics\n",
    "\n",
    "        # Log metrics for each class\n",
    "        metrics_each_label.pop(\"ConfusionMatrix\")\n",
    "        tensor_stack = torch.stack(list(metrics_each_label.values())).T\n",
    "        column_lists = [row.tolist() for row in tensor_stack]\n",
    "        change_metrics_each_class_table = wandb.Table(\n",
    "            columns=list(metrics_each_label.keys()),\n",
    "            data=column_lists,\n",
    "        )\n",
    "        run.log({f\"{metric_name}/table_each_class\": change_metrics_each_class_table})\n",
    "\n",
    "        # Log figures\n",
    "        run.log({f\"{metric_name}/confusion_matrix\": wandb.Image(figure_collection[0])})\n",
    "        run.log({f\"{metric_name}/accuracy_each_class\": wandb.Image(figure_collection[1])})\n",
    "        run.log({f\"{metric_name}/jaccard_each_class\": wandb.Image(figure_collection[2])})\n",
    "        run.log({f\"{metric_name}/precision_each_class\": wandb.Image(figure_collection[3])})\n",
    "        run.log({f\"{metric_name}/recall_each_class\": wandb.Image(figure_collection[4])})\n",
    "        run.log({f\"{metric_name}/f1score_each_class\": wandb.Image(figure_collection[5])})\n",
    "\n",
    "    elif num_classes > 2:\n",
    "        metric_name = \"change_metrics_2013_2020\"\n",
    "        # log Multiclass metrics\n",
    "        run.summary[metric_name] = multiclass_metrics\n",
    "\n",
    "        # Log metrics for each class\n",
    "        metrics_each_label.pop(\"ConfusionMatrix\")\n",
    "        tensor_stack = torch.stack(list(metrics_each_label.values())).T\n",
    "        column_lists = [row.tolist() for row in tensor_stack]\n",
    "        change_metrics_each_class_table = wandb.Table(\n",
    "            columns=list(metrics_each_label.keys()),\n",
    "            data=column_lists,\n",
    "        )\n",
    "        run.log({f\"{metric_name}/table_each_class\": change_metrics_each_class_table})\n",
    "\n",
    "        # Log figures\n",
    "        run.log({f\"{metric_name}/confusion_matrix\": wandb.Image(figure_collection[0])})\n",
    "        run.log({f\"{metric_name}/accuracy_each_class\": wandb.Image(figure_collection[1])})\n",
    "        run.log({f\"{metric_name}/jaccard_each_class\": wandb.Image(figure_collection[2])})\n",
    "        run.log({f\"{metric_name}/precision_each_class\": wandb.Image(figure_collection[3])})\n",
    "        run.log({f\"{metric_name}/recall_each_class\": wandb.Image(figure_collection[4])})\n",
    "        run.log({f\"{metric_name}/f1score_each_class\": wandb.Image(figure_collection[5])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Map with Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_change_map(\n",
    "    mask_path=data_folder / \"processed/mask/classes_v3_2003.tif\",\n",
    "    prediction_path=experiment_dir / \"roi_example_model-ocg72h08_v97_mIoU=0.3695.tif.tif\",\n",
    "    output_path=experiment_dir / \"change_map_2003-2013_roi_example-ocg72h08_v97.tif\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\n",
    "    \"No change\",\n",
    "    \"Mature Tree Density Loss\",\n",
    "    \"Old Growth Density Loss\",\n",
    "    \"Forest Setback YoungLoss\",\n",
    "    \"Forest Stage Progression\",\n",
    "    \"Forest Density Gain\",\n",
    "    \"Early Forest Establishment\",\n",
    "    \"Clearcut Loss\",\n",
    "    \"Other Transition\"]\n",
    "\n",
    "#class_names = [\n",
    "#    \"No change\",\n",
    "#    \"Change\"\n",
    "#]\n",
    "\n",
    "num_classes = len(class_names)\n",
    "\n",
    "multiclass_metrics, metrics_each_label, figure_collection = compute_final_metrics(\n",
    "    reference_change_map=data_folder / \"habitalp_change/habitalp_change_2013_2020.tif\",\n",
    "    prediction_change_map=experiment_dir / \"change_map_2003-2013-ocg72h08_v97.tif\",\n",
    "    num_classes=num_classes, # 9 classes to take no change and index into account\n",
    "    class_names=class_names,\n",
    ")\n",
    "\n",
    "print(multiclass_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with wandb.init(project=wandb_project, id=\"nt7lhzek\", resume=\"must\") as run:\n",
    "    if num_classes == 2:\n",
    "        metric_name = \"change_metrics_binary_2003-2013\"\n",
    "        # log Multiclass metrics\n",
    "        run.summary[metric_name] = multiclass_metrics\n",
    "\n",
    "        # Log metrics for each class\n",
    "        metrics_each_label.pop(\"ConfusionMatrix\")\n",
    "        tensor_stack = torch.stack(list(metrics_each_label.values())).T\n",
    "        column_lists = [row.tolist() for row in tensor_stack]\n",
    "        change_metrics_each_class_table = wandb.Table(\n",
    "            columns=list(metrics_each_label.keys()),\n",
    "            data=column_lists,\n",
    "        )\n",
    "        run.log({f\"{metric_name}/table_each_class\": change_metrics_each_class_table})\n",
    "\n",
    "        # Log figures\n",
    "        run.log({f\"{metric_name}/confusion_matrix\": wandb.Image(figure_collection[0])})\n",
    "        run.log({f\"{metric_name}/accuracy_each_class\": wandb.Image(figure_collection[1])})\n",
    "        run.log({f\"{metric_name}/jaccard_each_class\": wandb.Image(figure_collection[2])})\n",
    "        run.log({f\"{metric_name}/precision_each_class\": wandb.Image(figure_collection[3])})\n",
    "        run.log({f\"{metric_name}/recall_each_class\": wandb.Image(figure_collection[4])})\n",
    "        run.log({f\"{metric_name}/f1score_each_class\": wandb.Image(figure_collection[5])})\n",
    "\n",
    "    elif num_classes > 2:\n",
    "        metric_name = \"change_metrics_2003-2013\"\n",
    "        # log Multiclass metrics\n",
    "        run.summary[metric_name] = multiclass_metrics\n",
    "\n",
    "        # Log metrics for each class\n",
    "        metrics_each_label.pop(\"ConfusionMatrix\")\n",
    "        tensor_stack = torch.stack(list(metrics_each_label.values())).T\n",
    "        column_lists = [row.tolist() for row in tensor_stack]\n",
    "        change_metrics_each_class_table = wandb.Table(\n",
    "            columns=list(metrics_each_label.keys()),\n",
    "            data=column_lists,\n",
    "        )\n",
    "        run.log({f\"{metric_name}/table_each_class\": change_metrics_each_class_table})\n",
    "\n",
    "        # Log figures\n",
    "        run.log({f\"{metric_name}/confusion_matrix\": wandb.Image(figure_collection[0])})\n",
    "        run.log({f\"{metric_name}/accuracy_each_class\": wandb.Image(figure_collection[1])})\n",
    "        run.log({f\"{metric_name}/jaccard_each_class\": wandb.Image(figure_collection[2])})\n",
    "        run.log({f\"{metric_name}/precision_each_class\": wandb.Image(figure_collection[3])})\n",
    "        run.log({f\"{metric_name}/recall_each_class\": wandb.Image(figure_collection[4])})\n",
    "        run.log({f\"{metric_name}/f1score_each_class\": wandb.Image(figure_collection[5])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Physical Constraints Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.inference.utils import physical_constraints_module\n",
    "\n",
    "data_folder = Path(\"D:/Nextcloud/HabitAlp2.0/Originaldaten\")\n",
    "experiment_dir = data_folder / \"model_output/clay_v1_base_rgb_cir_ndsm/proability_weighted_bleding_for_inference\"\n",
    "\n",
    "mask_path = data_folder / \"processed/mask/classes_v3_2013.tif\"\n",
    "prediction_path = experiment_dir / \"prediction_training_roi_2_2020_Clayv1_64.tif\"\n",
    "dtm_path = data_folder / \"processed/elevation_gis_stmk_photogrammetry_2022_2023/dtm_2010_2012_aligned_cross-temporal_0.2m.tif\"\n",
    "slope_path = data_folder / \"processed/elevation_gis_stmk_photogrammetry_2022_2023/slope_2010_2012_aligned_cross-temporal_0.2m.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_constraints_module(\n",
    "    mask_path,\n",
    "    prediction_path,\n",
    "    dtm_path,\n",
    "    slope_path,\n",
    "    experiment_dir,\n",
    "    output_name=\"prediction_2020_roi_2_cross-temporal_with_constraint_violation_reset_to_mask\",\n",
    "    export_mask_for_each_constraint=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.inference.eval import generate_change_map\n",
    "\n",
    "generate_change_map(\n",
    "    mask_path=mask_path,\n",
    "    prediction_path=experiment_dir / \"prediction_2020_roi_1_cross-temporal_with_constraint_violation_reset_to_mask.tif\",\n",
    "    output_path=experiment_dir / \"change_map_cross-temporal_2020_roi_1_with_constraint_violation_reset_to_mask.tif\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.trainers.utils import compute_final_metrics\n",
    "\n",
    "class_names = [\n",
    "    \"No change\",\n",
    "    \"Mature Tree Density Loss\",\n",
    "    \"Old Growth Density Loss\",\n",
    "    \"Forest Setback YoungLoss\",\n",
    "    \"Forest Stage Progression\",\n",
    "    \"Forest Density Gain\",\n",
    "    \"Early Forest Establishment\",\n",
    "    \"Clearcut Loss\",\n",
    "    \"Other Transition\"]\n",
    "\n",
    "#class_names = [\n",
    "#    \"No change\",\n",
    "#    \"Change\"\n",
    "#]\n",
    "\n",
    "num_classes = len(class_names)\n",
    "\n",
    "multiclass_metrics, metrics_each_label, figure_collection = compute_final_metrics(\n",
    "    reference_change_map=data_folder / \"habitalp_change/habitalp_change_2013_2020.tif\",\n",
    "    prediction_change_map=experiment_dir / \"change_map_cross-temporal_2020_roi_1_with_constraint_violation_reset_to_mask.tif\",\n",
    "    num_classes=num_classes, # 9 classes to take no change and index into account\n",
    "    class_names=class_names,\n",
    ")\n",
    "\n",
    "print(multiclass_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shutdown OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.system(\"shutdown /s /t 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unet_cd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
